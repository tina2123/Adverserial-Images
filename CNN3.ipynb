{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tina2123/Adverserial-Images/blob/main/CNN3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sogvlhPNOVAx",
        "outputId": "880c01a8-c1c9-4ad5-b89e-019769bdd42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from tensorflow.keras import optimizers\n",
        " \n",
        " \n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        " \n",
        "#z-score\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        " \n",
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)\n",
        " \n",
        "baseMapNum = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        " \n",
        "model.summary()\n",
        " \n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        " \n",
        "#training\n",
        "batch_size = 64\n",
        "epochs=25\n",
        "opt_rms = keras.optimizers.RMSprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep75.h5')\n",
        " \n",
        "opt_rms = keras.optimizers.RMSprop(lr=0.0005,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep100.h5')\n",
        " \n",
        "opt_rms = keras.optimizers.RMSprop(lr=0.0003,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "        optimizer=opt_rms,\n",
        "        metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
        "model.save_weights('cifar10_normal_rms_ep125.h5')\n",
        " \n",
        "#testing - no kaggle eval\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From <ipython-input-2-3a4f742e0bd9>:84: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.9187 - accuracy: 0.4338 - val_loss: 1.2852 - val_accuracy: 0.5885\n",
            "Epoch 2/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 1.3267 - accuracy: 0.5927 - val_loss: 0.9883 - val_accuracy: 0.6886\n",
            "Epoch 3/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 1.1079 - accuracy: 0.6540 - val_loss: 0.9008 - val_accuracy: 0.7190\n",
            "Epoch 4/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.9923 - accuracy: 0.6955 - val_loss: 0.8549 - val_accuracy: 0.7441\n",
            "Epoch 5/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.9203 - accuracy: 0.7149 - val_loss: 0.9591 - val_accuracy: 0.7183\n",
            "Epoch 6/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.8668 - accuracy: 0.7352 - val_loss: 0.8178 - val_accuracy: 0.7527\n",
            "Epoch 7/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.8374 - accuracy: 0.7483 - val_loss: 0.8496 - val_accuracy: 0.7630\n",
            "Epoch 8/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.8019 - accuracy: 0.7597 - val_loss: 0.7108 - val_accuracy: 0.8028\n",
            "Epoch 9/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.7851 - accuracy: 0.7686 - val_loss: 0.7421 - val_accuracy: 0.7889\n",
            "Epoch 10/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.7688 - accuracy: 0.7757 - val_loss: 0.7576 - val_accuracy: 0.7871\n",
            "Epoch 11/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.7491 - accuracy: 0.7841 - val_loss: 0.6984 - val_accuracy: 0.8037\n",
            "Epoch 12/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.7336 - accuracy: 0.7900 - val_loss: 0.7454 - val_accuracy: 0.7889\n",
            "Epoch 13/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.7203 - accuracy: 0.7938 - val_loss: 0.7986 - val_accuracy: 0.7806\n",
            "Epoch 14/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.7139 - accuracy: 0.7966 - val_loss: 0.7132 - val_accuracy: 0.8067\n",
            "Epoch 15/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.7045 - accuracy: 0.8030 - val_loss: 0.7122 - val_accuracy: 0.8066\n",
            "Epoch 16/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.6949 - accuracy: 0.8051 - val_loss: 0.6525 - val_accuracy: 0.8249\n",
            "Epoch 17/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.6919 - accuracy: 0.8067 - val_loss: 0.6154 - val_accuracy: 0.8366\n",
            "Epoch 18/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.6804 - accuracy: 0.8116 - val_loss: 0.7167 - val_accuracy: 0.8086\n",
            "Epoch 19/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.6760 - accuracy: 0.8147 - val_loss: 0.6775 - val_accuracy: 0.8207\n",
            "Epoch 20/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6649 - accuracy: 0.8192 - val_loss: 0.6626 - val_accuracy: 0.8236\n",
            "Epoch 21/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6641 - accuracy: 0.8189 - val_loss: 0.6922 - val_accuracy: 0.8189\n",
            "Epoch 22/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.6582 - accuracy: 0.8226 - val_loss: 0.6515 - val_accuracy: 0.8239\n",
            "Epoch 23/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6523 - accuracy: 0.8224 - val_loss: 0.6483 - val_accuracy: 0.8351\n",
            "Epoch 24/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6552 - accuracy: 0.8234 - val_loss: 0.6277 - val_accuracy: 0.8341\n",
            "Epoch 25/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6520 - accuracy: 0.8250 - val_loss: 0.6559 - val_accuracy: 0.8280\n",
            "Epoch 26/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6447 - accuracy: 0.8270 - val_loss: 0.6209 - val_accuracy: 0.8438\n",
            "Epoch 27/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6403 - accuracy: 0.8295 - val_loss: 0.5910 - val_accuracy: 0.8475\n",
            "Epoch 28/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6411 - accuracy: 0.8282 - val_loss: 0.6163 - val_accuracy: 0.8383\n",
            "Epoch 29/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6392 - accuracy: 0.8298 - val_loss: 0.6864 - val_accuracy: 0.8211\n",
            "Epoch 30/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6324 - accuracy: 0.8331 - val_loss: 0.6532 - val_accuracy: 0.8302\n",
            "Epoch 31/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6333 - accuracy: 0.8326 - val_loss: 0.6264 - val_accuracy: 0.8409\n",
            "Epoch 32/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6265 - accuracy: 0.8346 - val_loss: 0.6117 - val_accuracy: 0.8497\n",
            "Epoch 33/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6247 - accuracy: 0.8351 - val_loss: 0.6124 - val_accuracy: 0.8448\n",
            "Epoch 34/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6268 - accuracy: 0.8350 - val_loss: 0.6538 - val_accuracy: 0.8412\n",
            "Epoch 35/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.6253 - accuracy: 0.8372 - val_loss: 0.6194 - val_accuracy: 0.8427\n",
            "Epoch 36/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6207 - accuracy: 0.8378 - val_loss: 0.6703 - val_accuracy: 0.8305\n",
            "Epoch 37/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6220 - accuracy: 0.8374 - val_loss: 0.5732 - val_accuracy: 0.8620\n",
            "Epoch 38/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6161 - accuracy: 0.8406 - val_loss: 0.5836 - val_accuracy: 0.8538\n",
            "Epoch 39/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6182 - accuracy: 0.8406 - val_loss: 0.6281 - val_accuracy: 0.8442\n",
            "Epoch 40/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6108 - accuracy: 0.8429 - val_loss: 0.5705 - val_accuracy: 0.8643\n",
            "Epoch 41/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6158 - accuracy: 0.8400 - val_loss: 0.6058 - val_accuracy: 0.8514\n",
            "Epoch 42/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6068 - accuracy: 0.8439 - val_loss: 0.6471 - val_accuracy: 0.8405\n",
            "Epoch 43/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6056 - accuracy: 0.8443 - val_loss: 0.5716 - val_accuracy: 0.8626\n",
            "Epoch 44/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6073 - accuracy: 0.8423 - val_loss: 0.6191 - val_accuracy: 0.8459\n",
            "Epoch 45/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6039 - accuracy: 0.8439 - val_loss: 0.5837 - val_accuracy: 0.8566\n",
            "Epoch 46/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6053 - accuracy: 0.8442 - val_loss: 0.6008 - val_accuracy: 0.8514\n",
            "Epoch 47/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5989 - accuracy: 0.8473 - val_loss: 0.6371 - val_accuracy: 0.8379\n",
            "Epoch 48/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.6007 - accuracy: 0.8455 - val_loss: 0.6764 - val_accuracy: 0.8354\n",
            "Epoch 49/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5992 - accuracy: 0.8477 - val_loss: 0.6031 - val_accuracy: 0.8542\n",
            "Epoch 50/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5950 - accuracy: 0.8479 - val_loss: 0.6605 - val_accuracy: 0.8332\n",
            "Epoch 51/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5952 - accuracy: 0.8479 - val_loss: 0.6150 - val_accuracy: 0.8509\n",
            "Epoch 52/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5956 - accuracy: 0.8493 - val_loss: 0.6317 - val_accuracy: 0.8441\n",
            "Epoch 53/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5935 - accuracy: 0.8491 - val_loss: 0.5925 - val_accuracy: 0.8532\n",
            "Epoch 54/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5962 - accuracy: 0.8476 - val_loss: 0.6137 - val_accuracy: 0.8483\n",
            "Epoch 55/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5903 - accuracy: 0.8481 - val_loss: 0.5840 - val_accuracy: 0.8617\n",
            "Epoch 56/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5906 - accuracy: 0.8502 - val_loss: 0.6582 - val_accuracy: 0.8331\n",
            "Epoch 57/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5896 - accuracy: 0.8493 - val_loss: 0.5774 - val_accuracy: 0.8616\n",
            "Epoch 58/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5882 - accuracy: 0.8502 - val_loss: 0.5742 - val_accuracy: 0.8595\n",
            "Epoch 59/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5906 - accuracy: 0.8508 - val_loss: 0.5718 - val_accuracy: 0.8645\n",
            "Epoch 60/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5894 - accuracy: 0.8497 - val_loss: 0.6633 - val_accuracy: 0.8375\n",
            "Epoch 61/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5819 - accuracy: 0.8528 - val_loss: 0.5841 - val_accuracy: 0.8571\n",
            "Epoch 62/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5875 - accuracy: 0.8531 - val_loss: 0.6176 - val_accuracy: 0.8530\n",
            "Epoch 63/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5881 - accuracy: 0.8498 - val_loss: 0.6455 - val_accuracy: 0.8420\n",
            "Epoch 64/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5864 - accuracy: 0.8515 - val_loss: 0.6783 - val_accuracy: 0.8296\n",
            "Epoch 65/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5844 - accuracy: 0.8518 - val_loss: 0.6356 - val_accuracy: 0.8485\n",
            "Epoch 66/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5823 - accuracy: 0.8552 - val_loss: 0.6442 - val_accuracy: 0.8479\n",
            "Epoch 67/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5816 - accuracy: 0.8546 - val_loss: 0.6288 - val_accuracy: 0.8506\n",
            "Epoch 68/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5789 - accuracy: 0.8556 - val_loss: 0.5699 - val_accuracy: 0.8634\n",
            "Epoch 69/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.5771 - accuracy: 0.8551 - val_loss: 0.5690 - val_accuracy: 0.8654\n",
            "Epoch 70/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.5775 - accuracy: 0.8563 - val_loss: 0.5657 - val_accuracy: 0.8652\n",
            "Epoch 71/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.5770 - accuracy: 0.8553 - val_loss: 0.5968 - val_accuracy: 0.8551\n",
            "Epoch 72/75\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 0.5784 - accuracy: 0.8562 - val_loss: 0.5612 - val_accuracy: 0.8637\n",
            "Epoch 73/75\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 0.5748 - accuracy: 0.8562 - val_loss: 0.6479 - val_accuracy: 0.8403\n",
            "Epoch 74/75\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5775 - accuracy: 0.8533 - val_loss: 0.5877 - val_accuracy: 0.8581\n",
            "Epoch 75/75\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5801 - accuracy: 0.8539 - val_loss: 0.6250 - val_accuracy: 0.8411\n",
            "Epoch 1/25\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.5339 - accuracy: 0.8692 - val_loss: 0.5193 - val_accuracy: 0.8768\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5167 - accuracy: 0.8746 - val_loss: 0.5269 - val_accuracy: 0.8781\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5101 - accuracy: 0.8753 - val_loss: 0.5254 - val_accuracy: 0.8724\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5039 - accuracy: 0.8752 - val_loss: 0.5196 - val_accuracy: 0.8784\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4970 - accuracy: 0.8787 - val_loss: 0.5056 - val_accuracy: 0.8793\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4893 - accuracy: 0.8790 - val_loss: 0.5270 - val_accuracy: 0.8726\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4920 - accuracy: 0.8791 - val_loss: 0.5436 - val_accuracy: 0.8726\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4872 - accuracy: 0.8790 - val_loss: 0.5328 - val_accuracy: 0.8744\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4840 - accuracy: 0.8796 - val_loss: 0.5375 - val_accuracy: 0.8716\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4851 - accuracy: 0.8782 - val_loss: 0.5106 - val_accuracy: 0.8775\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4806 - accuracy: 0.8800 - val_loss: 0.4953 - val_accuracy: 0.8799\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4770 - accuracy: 0.8804 - val_loss: 0.5240 - val_accuracy: 0.8727\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4785 - accuracy: 0.8802 - val_loss: 0.4981 - val_accuracy: 0.8800\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4681 - accuracy: 0.8832 - val_loss: 0.5772 - val_accuracy: 0.8567\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4710 - accuracy: 0.8813 - val_loss: 0.4934 - val_accuracy: 0.8794\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4707 - accuracy: 0.8802 - val_loss: 0.4916 - val_accuracy: 0.8830\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4712 - accuracy: 0.8783 - val_loss: 0.5082 - val_accuracy: 0.8766\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4673 - accuracy: 0.8820 - val_loss: 0.5071 - val_accuracy: 0.8743\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4674 - accuracy: 0.8819 - val_loss: 0.4868 - val_accuracy: 0.8847\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4655 - accuracy: 0.8823 - val_loss: 0.5550 - val_accuracy: 0.8611\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4654 - accuracy: 0.8820 - val_loss: 0.4993 - val_accuracy: 0.8771\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4657 - accuracy: 0.8815 - val_loss: 0.5058 - val_accuracy: 0.8753\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4615 - accuracy: 0.8831 - val_loss: 0.5605 - val_accuracy: 0.8587\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4577 - accuracy: 0.8845 - val_loss: 0.5082 - val_accuracy: 0.8744\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4595 - accuracy: 0.8829 - val_loss: 0.5278 - val_accuracy: 0.8651\n",
            "Epoch 1/25\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4413 - accuracy: 0.8889 - val_loss: 0.4615 - val_accuracy: 0.8870\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4301 - accuracy: 0.8918 - val_loss: 0.4760 - val_accuracy: 0.8861\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4311 - accuracy: 0.8914 - val_loss: 0.5142 - val_accuracy: 0.8737\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4231 - accuracy: 0.8941 - val_loss: 0.4676 - val_accuracy: 0.8880\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4263 - accuracy: 0.8922 - val_loss: 0.4778 - val_accuracy: 0.8811\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4185 - accuracy: 0.8943 - val_loss: 0.4622 - val_accuracy: 0.8893\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4202 - accuracy: 0.8928 - val_loss: 0.4612 - val_accuracy: 0.8885\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4176 - accuracy: 0.8954 - val_loss: 0.4682 - val_accuracy: 0.8832\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4128 - accuracy: 0.8951 - val_loss: 0.5258 - val_accuracy: 0.8715\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.4159 - accuracy: 0.8941 - val_loss: 0.4578 - val_accuracy: 0.8884\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4127 - accuracy: 0.8953 - val_loss: 0.4752 - val_accuracy: 0.8809\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4091 - accuracy: 0.8953 - val_loss: 0.4760 - val_accuracy: 0.8813\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4088 - accuracy: 0.8967 - val_loss: 0.4847 - val_accuracy: 0.8795\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4038 - accuracy: 0.8983 - val_loss: 0.4825 - val_accuracy: 0.8806\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4075 - accuracy: 0.8967 - val_loss: 0.4707 - val_accuracy: 0.8838\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4055 - accuracy: 0.8962 - val_loss: 0.4511 - val_accuracy: 0.8873\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4036 - accuracy: 0.8971 - val_loss: 0.4650 - val_accuracy: 0.8847\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4041 - accuracy: 0.8970 - val_loss: 0.4799 - val_accuracy: 0.8803\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4026 - accuracy: 0.8947 - val_loss: 0.4488 - val_accuracy: 0.8895\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4000 - accuracy: 0.8972 - val_loss: 0.4575 - val_accuracy: 0.8858\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4009 - accuracy: 0.8961 - val_loss: 0.4438 - val_accuracy: 0.8915\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3964 - accuracy: 0.8982 - val_loss: 0.4569 - val_accuracy: 0.8873\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4026 - accuracy: 0.8962 - val_loss: 0.5064 - val_accuracy: 0.8745\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3975 - accuracy: 0.8961 - val_loss: 0.4412 - val_accuracy: 0.8923\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3972 - accuracy: 0.8970 - val_loss: 0.4657 - val_accuracy: 0.8824\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.8824\n",
            "\n",
            "Test result: 88.240 loss: 0.466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZaNtsTdHttB"
      },
      "source": [
        "#saving the model to colab\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/CIFAR10Model.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us59Va7QV_2J",
        "outputId": "2145e9ff-2477-4af1-a074-8082f8910c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#save model to google drive follow this toturial (https://medium.com/@ml_kid/how-to-save-our-model-to-google-drive-and-reuse-it-2c1028058cb2)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noIGKxB2YEGf"
      },
      "source": [
        "model_save_name = 'CIFAR10Model.h5'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "model.save(path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2d73tkteX8M",
        "outputId": "a9c82a68-2b43-4d0f-b82c-bdcdd5f8977a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "trainedModel = load_model(path)\n",
        "trainedModel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYVnzb39SpN6",
        "outputId": "e7bab605-1a60-4604-8fdc-06196930cf15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#loading the model after saving\n",
        "new_model = tf.keras.models.load_model('saved_model/CIFAR10Model.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVubT1m3Snax"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G751g_jbO-ak",
        "outputId": "eaebc1ff-f4ef-4c5e-c282-625de59486ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "pip show tensorflow\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.3.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: google-pasta, absl-py, astunparse, tensorflow-estimator, wheel, scipy, keras-preprocessing, h5py, opt-einsum, tensorboard, termcolor, gast, protobuf, wrapt, numpy, grpcio, six\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}